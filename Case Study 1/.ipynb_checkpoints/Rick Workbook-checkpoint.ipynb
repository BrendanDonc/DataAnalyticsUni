{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('STUDENT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1044 entries, 0 to 1043\n",
      "Data columns (total 35 columns):\n",
      "id             1044 non-null int64\n",
      "InitialName    1044 non-null object\n",
      "school         992 non-null object\n",
      "sex            1044 non-null object\n",
      "age            971 non-null float64\n",
      "address        1044 non-null object\n",
      "famsize        1044 non-null object\n",
      "Pstatus        1044 non-null object\n",
      "Medu           1044 non-null int64\n",
      "Fedu           1044 non-null int64\n",
      "Mjob           1044 non-null object\n",
      "Fjob           1044 non-null object\n",
      "reason         428 non-null object\n",
      "guardian       1044 non-null object\n",
      "traveltime     1044 non-null int64\n",
      "studytime      1044 non-null int64\n",
      "failures       1044 non-null int64\n",
      "schoolsup      1044 non-null object\n",
      "famsup         1044 non-null object\n",
      "paid           1044 non-null object\n",
      "activities     1044 non-null object\n",
      "nursery        1044 non-null object\n",
      "higher         1044 non-null object\n",
      "internet       1044 non-null object\n",
      "romantic       1044 non-null object\n",
      "famrel         1044 non-null int64\n",
      "freetime       1044 non-null int64\n",
      "goout          1044 non-null int64\n",
      "Dalc           1044 non-null int64\n",
      "Walc           1044 non-null int64\n",
      "health         1044 non-null int64\n",
      "absences       1044 non-null int64\n",
      "G1             1013 non-null float64\n",
      "G2             1013 non-null float64\n",
      "G3             1044 non-null object\n",
      "dtypes: float64(3), int64(13), object(19)\n",
      "memory usage: 285.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PASS    661\n",
       "FAIL    383\n",
       "Name: G3, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1.1\n",
    "df['G3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1.2\n",
    "def preprocess():\n",
    "    import pandas as pd\n",
    "    #Preprocess data\n",
    "    df_raw = pd.read_csv('STUDENT.csv', index_col=0)\n",
    "    df = df_raw.drop(['InitialName', 'guardian'], axis=1)\n",
    "    \n",
    "    #Map binaries\n",
    "    df['address'] = df['address'].map({ 'U':0, 'R':1 })\n",
    "    df['sex'] = df['sex'].map({ 'M':0, 'F':1 })\n",
    "    df['famsize'] = df['famsize'].map({ 'LE3':0, 'GT3':1 })\n",
    "    df['Pstatus'] = df['Pstatus'].map({ 'A':0, 'T':1 })\n",
    "    df['schoolsup'] = df['schoolsup'].map({ 'no':0, 'yes':1 })\n",
    "    df['famsup'] = df['famsup'].map({ 'no':0, 'yes':1 })\n",
    "    df['paid'] = df['paid'].map({ 'no':0, 'yes':1 })\n",
    "    df['activities'] = df['activities'].map({ 'no':0, 'yes':1 })\n",
    "    df['nursery'] = df['nursery'].map({ 'no':0, 'yes':1 })\n",
    "    df['higher'] = df['higher'].map({ 'no':0, 'yes':1 })\n",
    "    df['internet'] = df['internet'].map({ 'no':0, 'yes':1 })\n",
    "    df['romantic'] = df['romantic'].map({ 'no':0, 'yes':1 })\n",
    "    df['G3'] = df['G3'].map({ 'FAIL': 0, 'PASS': 1 })\n",
    "\n",
    "    #Fill via median for age\n",
    "    df['age'].fillna(df['age'].median(), inplace=True)\n",
    "    \n",
    "    #Fill via 'none' since hot encode will flag\n",
    "    df['school'].fillna('none', inplace=True)\n",
    "    df['reason'].fillna('none', inplace=True)\n",
    "\n",
    "    #Drop g1 & 2 empty rows\n",
    "    df = df.drop(['G1', 'G2', 'failures'], axis=1)\n",
    "    #cols_miss_drop =['G1', 'G2']\n",
    "    #mask = pd.isnull(df['G1'])\n",
    "    #for col in cols_miss_drop:\n",
    "    # mask = mask | pd.isnull(df[col])\n",
    "    #df = df[~mask]\n",
    "\n",
    "    #Hot encode\n",
    "    df = pd.get_dummies(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_feature_importance(dm_model, feature_names, n_to_display=20):\n",
    "    # grab feature importances from the model\n",
    "    importances = dm_model.feature_importances_\n",
    "\n",
    "    # sort them out in descending order\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "    # limit to 20 features, you can leave this out to print out everything\n",
    "    indices = indices[:n_to_display]\n",
    "    for i in indices:\n",
    "        print(feature_names[i], ':', importances[i])\n",
    "        \n",
    "def visualize_decision_tree(dm_model, feature_names, save_name):\n",
    "    dotfile = StringIO()\n",
    "    export_graphviz(dm_model, out_file=dotfile, feature_names=feature_names)\n",
    "    graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "    graph.write_png(save_name) # saved in the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1044 entries, 0 to 1043\n",
      "Data columns (total 43 columns):\n",
      "sex                  1044 non-null int64\n",
      "age                  1044 non-null float64\n",
      "address              1044 non-null int64\n",
      "famsize              1044 non-null int64\n",
      "Pstatus              1044 non-null int64\n",
      "Medu                 1044 non-null int64\n",
      "Fedu                 1044 non-null int64\n",
      "traveltime           1044 non-null int64\n",
      "studytime            1044 non-null int64\n",
      "schoolsup            1044 non-null int64\n",
      "famsup               1044 non-null int64\n",
      "paid                 1044 non-null int64\n",
      "activities           1044 non-null int64\n",
      "nursery              1044 non-null int64\n",
      "higher               1044 non-null int64\n",
      "internet             1044 non-null int64\n",
      "romantic             1044 non-null int64\n",
      "famrel               1044 non-null int64\n",
      "freetime             1044 non-null int64\n",
      "goout                1044 non-null int64\n",
      "Dalc                 1044 non-null int64\n",
      "Walc                 1044 non-null int64\n",
      "health               1044 non-null int64\n",
      "absences             1044 non-null int64\n",
      "G3                   1044 non-null int64\n",
      "school_DCHS          1044 non-null uint8\n",
      "school_THS           1044 non-null uint8\n",
      "school_none          1044 non-null uint8\n",
      "Mjob_at_home         1044 non-null uint8\n",
      "Mjob_health          1044 non-null uint8\n",
      "Mjob_other           1044 non-null uint8\n",
      "Mjob_services        1044 non-null uint8\n",
      "Mjob_teacher         1044 non-null uint8\n",
      "Fjob_at_home         1044 non-null uint8\n",
      "Fjob_health          1044 non-null uint8\n",
      "Fjob_other           1044 non-null uint8\n",
      "Fjob_services        1044 non-null uint8\n",
      "Fjob_teacher         1044 non-null uint8\n",
      "reason_course        1044 non-null uint8\n",
      "reason_home          1044 non-null uint8\n",
      "reason_none          1044 non-null uint8\n",
      "reason_other         1044 non-null uint8\n",
      "reason_reputation    1044 non-null uint8\n",
      "dtypes: float64(1), int64(24), uint8(18)\n",
      "memory usage: 230.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = preprocess()\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    955\n",
       "0     89\n",
       "Name: higher, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['higher'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    992\n",
       "1     52\n",
       "Name: school_none, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['school_none'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9972602739726028\n",
      "Test accuracy: 0.589171974522293\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.50      0.47       115\n",
      "          1       0.69      0.64      0.66       199\n",
      "\n",
      "avg / total       0.60      0.59      0.59       314\n",
      "\n",
      "absences : 0.09560916279923631\n",
      "higher : 0.06658724391357355\n",
      "age : 0.06262717342173142\n",
      "Fedu : 0.05760027257597375\n",
      "traveltime : 0.043278515973278565\n",
      "freetime : 0.042289114645506304\n",
      "famrel : 0.041627954427609797\n",
      "goout : 0.040205962439106256\n",
      "health : 0.038198143545094314\n",
      "reason_home : 0.03687757908823\n",
      "famsup : 0.036806554546183756\n",
      "Medu : 0.035631807393326664\n",
      "studytime : 0.0338949196526395\n",
      "sex : 0.0272595931558402\n",
      "school_DCHS : 0.026589526320946126\n",
      "Dalc : 0.025552026252349605\n",
      "Walc : 0.0235540199840252\n",
      "internet : 0.022752062565688812\n",
      "paid : 0.021111823615985976\n",
      "Mjob_at_home : 0.019885283725948007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rickm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y = df['G3']\n",
    "x = df.drop(['G3'], axis=1)\n",
    "\n",
    "#set seed for randomisation\n",
    "rs = 10\n",
    "\n",
    "#Convert x into numpy matrix for sklearn consumption\n",
    "x_mat = x.as_matrix()\n",
    "#Setup training and test datasets on a 70/30 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n",
    "#simple decision tree training\n",
    "model = DecisionTreeClassifier(random_state=rs)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Check accuracy on the training sets\n",
    "print(\"Train accuracy:\", model.score(x_train, y_train))\n",
    "#Check accuracy on the test sets\n",
    "print(\"Test accuracy:\", model.score(x_test, y_test))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Check which features have the largest impact on the decision tree?\n",
    "import numpy as np\n",
    "\n",
    "#grab feature importances from the model and feature name from the original x\n",
    "importances = model.feature_importances_\n",
    "feature_names = x.columns\n",
    "\n",
    "#sort in descending order\n",
    "indices = np.argsort(importances)\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "#limit to 20 features\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', importances[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "from io import StringIO\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "from sklearn.tree import export_graphviz\n",
    "# visualize\n",
    "dotfile = StringIO()\n",
    "export_graphviz(model, out_file=dotfile, feature_names=x.columns)\n",
    "graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "graph[0].write_png(\"optimal-default_decision.png\") # saved in the following file - will return True if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7219178082191781\n",
      "Test accuracy: 0.6592356687898089\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.50      0.52       115\n",
      "          1       0.72      0.75      0.74       199\n",
      "\n",
      "avg / total       0.65      0.66      0.66       314\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    " 'max_depth': range(2, 10),\n",
    " 'min_samples_leaf': range(20, 60, 10)}\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs),cv=10)\n",
    "cv.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "# test the best model\n",
    "y_pred = cv.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search CV\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    " 'max_depth': range(2, 10),\n",
    " 'min_samples_leaf': range(24, 37)}\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs),cv=10)\n",
    "cv.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "# test the best model\n",
    "y_pred = cv.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_feature_importance(cv.best_estimator_, x.columns, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_decision_tree(cv.best_estimator_, x.columns, \"brendan-optimal_decision.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Start of regression\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all data to have a mean of 0\n",
    "x_train_scaler = scaler.fit_transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=rs)\n",
    "# fit it to training data\n",
    "model.fit(x_train_scaler, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test accuracy\n",
    "print(\"Train accuracy:\", model.score(x_train_scaler, y_train))\n",
    "print(\"Test accuracy:\", model.score(x_test, y_test))\n",
    "# classification report on test data\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = x.columns\n",
    "coef = model.coef_[0]\n",
    "# limit to 20 features, you can comment the following line to print out everything\n",
    "coef = coef[:20]\n",
    "for i in range(len(coef)):\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab feature importances from the model and feature name from the original X\n",
    "coef = model.coef_[0]\n",
    "feature_names = x.columns\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-8, 6)]}\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs),cv=10, n_jobs=-1)\n",
    "cv.fit(x_train, y_train)\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(x_train_scaler, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "y_pred = cv.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Only able to be done on continous I think??\n",
    "#\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_skewed_columns(df):\n",
    "    # setting up subplots for easier visualisation\n",
    "    f, axes = plt.subplots(1,2, figsize=(10,10), sharex=False)\n",
    "    # gift avg plots\n",
    "    sns.distplot(df['age'].dropna(), hist=False, ax=axes[0])\n",
    "    sns.distplot(df['absences'].dropna(), hist=False, ax=axes[1])\n",
    "    plt.show()\n",
    "\n",
    "plot_skewed_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# list columns to be transformed\n",
    "columns_to_transform = ['absences', 'age']\n",
    "# copy the dataframe\n",
    "df_log = df.copy()\n",
    "# transform the columns with np.log\n",
    "for col in columns_to_transform:\n",
    "    df_log[col] = df_log[col].apply(lambda x: x+1)\n",
    "    df_log[col] = df_log[col].apply(np.log)\n",
    "# plot them again to show the distribution\n",
    "plot_skewed_columns(df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = df_log['G3']\n",
    "x_log = df_log.drop(['G3'], axis=1)\n",
    "x_mat_log = x_log.as_matrix()\n",
    "x_train_log, x_test_log, y_train_log, y_test_log = train_test_split(x_mat_log, y_log, test_size=0.3, \n",
    "                                                                    stratify=y_log, random_state=rs)\n",
    "# standardise them again\n",
    "scaler_log = StandardScaler()\n",
    "x_train_log = scaler_log.fit_transform(x_train_log, y_train_log)\n",
    "x_test_log = scaler_log.transform(x_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs),\n",
    "cv=10, n_jobs=-1)\n",
    "cv.fit(x_train_log, y_train_log)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(x_train_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(x_test_log, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(x_test_log)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Log made it worse\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(x_train, y_train) # run the RFECV\n",
    "# comparing how many variables before and after\n",
    "print(\"Original feature set\", x_train.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sel = rfe.transform(x_train)\n",
    "x_test_sel = rfe.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs),\n",
    "cv=10, n_jobs=-1)\n",
    "cv.fit(x_train_sel, y_train)\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(x_train_sel, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test_sel, y_test))\n",
    "y_pred = cv.predict(x_test_sel)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running RFE + log transformation\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(x_train_log, y_train_log) # run the RFECV on log transformed dataset\n",
    "# comparing how many variables before and after\n",
    "print(\"Original feature set\", x_train_log.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)\n",
    "# select features from log transformed dataset\n",
    "x_train_sel_log = rfe.transform(x_train_log)\n",
    "x_test_sel_log = rfe.transform(x_test_log)\n",
    "# init grid search CV on transformed dataset\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs),\n",
    "cv=10, n_jobs=-1)\n",
    "cv.fit(x_train_sel_log, y_train_log)\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(x_train_sel_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(x_test_sel_log, y_test_log))\n",
    "y_pred_log = cv.predict(x_test_sel_log)\n",
    "print(classification_report(y_test_log, y_pred_log))\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# RFE + log is better than RFE or log but original is better than both\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar parameters with the last practical\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "'max_depth': range(3, 9),\n",
    "'min_samples_leaf': range(25, 45)}\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(x_train_log, y_train_log)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "# use the trained best decision tree from GridSearchCV to select features\n",
    "# supply the prefit=True parameter to stop SelectFromModel to re-train the model\n",
    "selectmodel = SelectFromModel(cv.best_estimator_, prefit=True)\n",
    "x_train_sel_model = selectmodel.transform(x_train_log)\n",
    "x_test_sel_model = selectmodel.transform(x_test_log)\n",
    "print(x_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_feature_importance(cv.best_estimator_, x_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs),\n",
    "cv=10, n_jobs=-1)\n",
    "cv.fit(x_train_sel_model, y_train_log)\n",
    "print(\"Train accuracy:\", cv.score(x_train_sel_model, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(x_test_sel_model, y_test_log))\n",
    "# test the best model\n",
    "y_pred = cv.predict(x_test_sel_model)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Still not as good as just normal\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
