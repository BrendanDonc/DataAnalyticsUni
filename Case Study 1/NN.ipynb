{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moved this into its own file as neural network modelling can take a while\n",
    "#Will move back in once finished testing with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from preprocess import preprocess\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rickm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = preprocess()\n",
    "rs = 0\n",
    "\n",
    "y = df['G3']\n",
    "x = df.drop(['G3'], axis=1)\n",
    "x_mat = x.as_matrix()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train, y_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9863013698630136\n",
      "Test accuracy: 0.6528662420382165\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.62      0.57       115\n",
      "          1       0.75      0.67      0.71       199\n",
      "\n",
      "avg / total       0.67      0.65      0.66       314\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rickm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Using the base inputs for MachineLearn\n",
    "#Extremely overfit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(max_iter=200, random_state=rs)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(x_test, y_test))\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 42)\n"
     ]
    }
   ],
   "source": [
    "#Find shape to outline potential neuron amount\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9904109589041096\n",
      "Test accuracy: 0.6178343949044586\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.57      0.52       115\n",
      "          1       0.72      0.65      0.68       199\n",
      "\n",
      "avg / total       0.63      0.62      0.62       314\n",
      "\n",
      "{'hidden_layer_sizes': (25,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(x,) for x in range(2, 43, 20)]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(max_iter=700, random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "y_pred = cv.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7794520547945205\n",
      "Test accuracy: 0.6560509554140127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.57      0.55       115\n",
      "          1       0.74      0.71      0.72       199\n",
      "\n",
      "avg / total       0.66      0.66      0.66       314\n",
      "\n",
      "{'hidden_layer_sizes': (3,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(x,) for x in range(1, 5, 1)]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(max_iter=700, random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "y_pred = cv.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7794520547945205\n",
      "Test accuracy: 0.6560509554140127\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.57      0.55       115\n",
      "          1       0.74      0.71      0.72       199\n",
      "\n",
      "avg / total       0.66      0.66      0.66       314\n",
      "\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': 3}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(3)], 'alpha': [0.01,0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(max_iter=700, random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(x_train, y_train)\n",
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "y_pred = cv.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rickm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# list columns to be transformed\n",
    "columns_to_transform = ['absences', 'age']\n",
    "# copy the dataframe\n",
    "df_log = df.copy()\n",
    "# transform the columns with np.log\n",
    "for col in columns_to_transform:\n",
    "    df_log[col] = df_log[col].apply(lambda x: x+1)\n",
    "    df_log[col] = df_log[col].apply(np.log)\n",
    "y_log = df_log['G3']\n",
    "x_log = df_log.drop(['G3'], axis=1)\n",
    "x_mat_log = x_log.as_matrix()\n",
    "x_train_log, x_test_log, y_train_log, y_test_log = train_test_split(x_mat_log, y_log, test_size=0.3, stratify=y_log,random_state=rs)\n",
    "# standardise them again\n",
    "scaler_log = StandardScaler()\n",
    "x_train_log = scaler_log.fit_transform(x_train_log, y_train_log)\n",
    "x_test_log = scaler_log.transform(x_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.836986301369863\n",
      "Test accuracy: 0.6464968152866242\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.53      0.52       115\n",
      "          1       0.72      0.71      0.72       199\n",
      "\n",
      "avg / total       0.65      0.65      0.65       314\n",
      "\n",
      "{'alpha': 1e-05, 'hidden_layer_sizes': (4,)}\n"
     ]
    }
   ],
   "source": [
    "#Look for improvements using transofrmed log\n",
    "params = {'hidden_layer_sizes': [(x,) for x in range(3, 5, 1)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(max_iter=1000, random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(x_train_log, y_train_log)\n",
    "print(\"Train accuracy:\", cv.score(x_train_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(x_test_log, y_test_log))\n",
    "y_pred = cv.predict(x_test_log)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "print(cv.best_params_)\n",
    "#doesnt improve..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(x_train_log, y_train_log)\n",
    "print(rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7493150684931507\n",
      "Test accuracy: 0.6910828025477707\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.47      0.53       115\n",
      "          1       0.73      0.82      0.77       199\n",
      "\n",
      "avg / total       0.68      0.69      0.68       314\n",
      "\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (3,)}\n"
     ]
    }
   ],
   "source": [
    "# transform log\n",
    "x_train_rfe = rfe.transform(x_train_log)\n",
    "x_test_rfe = rfe.transform(x_test_log)\n",
    "# step = int((X_train_rfe.shape[1] + 5)/5);\n",
    "params = {'hidden_layer_sizes': [(x,) for x in range(2, 8, 1)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(max_iter=700, random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(x_train_rfe, y_train_log)\n",
    "print(\"Train accuracy:\", cv.score(x_train_rfe, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(x_test_rfe, y_test_log))\n",
    "y_pred = cv.predict(x_test_rfe)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "print(cv.best_params_)\n",
    "#Sees improvement & overfitting reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': range(3, 8), 'min_samples_leaf': range(20, 61, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "'max_depth': range(3, 8),\n",
    "'min_samples_leaf': range(20, 61, 10)}\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(x_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "higher : 0.5329224394515739\n",
      "absences : 0.25645586308146323\n",
      "school_DCHS : 0.21062169746696274\n",
      "reason_reputation : 0.0\n",
      "goout : 0.0\n",
      "famrel : 0.0\n",
      "romantic : 0.0\n",
      "internet : 0.0\n",
      "nursery : 0.0\n",
      "activities : 0.0\n",
      "paid : 0.0\n",
      "famsup : 0.0\n",
      "schoolsup : 0.0\n",
      "studytime : 0.0\n",
      "traveltime : 0.0\n",
      "Fedu : 0.0\n",
      "Medu : 0.0\n",
      "Pstatus : 0.0\n",
      "famsize : 0.0\n",
      "address : 0.0\n"
     ]
    }
   ],
   "source": [
    "from tools import analyse_feature_importance\n",
    "analyse_feature_importance(cv.best_estimator_, x_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "selectmodel = SelectFromModel(cv.best_estimator_, prefit=True)\n",
    "x_train_sel_model = selectmodel.transform(x_train)\n",
    "x_test_sel_model = selectmodel.transform(x_test)\n",
    "print(x_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6972602739726027\n",
      "Test accuracy: 0.6815286624203821\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.28      0.39       115\n",
      "          1       0.69      0.91      0.78       199\n",
      "\n",
      "avg / total       0.67      0.68      0.64       314\n",
      "\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (7,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(x,) for x in range(2, 8, 1)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(x_train_sel_model, y_train)\n",
    "print(\"Train accuracy:\", cv.score(x_train_sel_model, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test_sel_model, y_test))\n",
    "y_pred = cv.predict(x_test_sel_model)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(cv.best_params_)\n",
    "#not an improvement over previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
